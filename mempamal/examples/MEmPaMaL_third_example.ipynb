{
 "metadata": {
  "name": "",
  "signature": "sha256:c93595997cc8a1f94a2539e630f7ee0acc067fca6890afd45082457971b54979"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from sklearn.cross_validation import StratifiedKFold\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.metrics import r2_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mempamal.configuration import JSONify_estimator, JSONify_cv, build_dataset\n",
      "from mempamal.examples.elasticnet_parsimony import EnetWrap\n",
      "from mempamal.workflow import create_wf, save_wf\n",
      "from mempamal.datasets import iris"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "X, y = iris.get_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "est = Pipeline([(\"enet\", EnetWrap())])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import inspect\n",
      "print(inspect.getsource(inspect.getmodule(EnetWrap)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "from parsimony.estimators import ElasticNet\n",
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "\n",
        "class EnetWrap(BaseEstimator, ElasticNet):\n",
        "\n",
        "    def __init__(self, l=0., alpha=1., algorithm_params={},\n",
        "                 penalty_start=0, mean=True):\n",
        "        super(EnetWrap, self).__init__(l=l, alpha=alpha,\n",
        "                                       algorithm_params=algorithm_params,\n",
        "                                       penalty_start=penalty_start, mean=mean)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alphas = [1e-4, 1e-3, 1e-2, 0.1, 1., 10., 100., 1e3]\n",
      "ls = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
      "grid = []\n",
      "for a in alphas:\n",
      "    for l in ls:\n",
      "        grid.append({\"enet__l\": l,\n",
      "                     \"enet__alpha\": a})\n",
      "print(\"The grid contains {} sets of parameters:\".format(len(grid)))\n",
      "grid"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The grid contains 72 sets of parameters:\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "[{'enet__alpha': 0.0001, 'enet__l': 0.1},\n",
        " {'enet__alpha': 0.0001, 'enet__l': 0.2},\n",
        " {'enet__alpha': 0.0001, 'enet__l': 0.3},\n",
        " {'enet__alpha': 0.0001, 'enet__l': 0.4},\n",
        " {'enet__alpha': 0.0001, 'enet__l': 0.5},\n",
        " {'enet__alpha': 0.0001, 'enet__l': 0.6},\n",
        " {'enet__alpha': 0.0001, 'enet__l': 0.7},\n",
        " {'enet__alpha': 0.0001, 'enet__l': 0.8},\n",
        " {'enet__alpha': 0.0001, 'enet__l': 0.9},\n",
        " {'enet__alpha': 0.001, 'enet__l': 0.1},\n",
        " {'enet__alpha': 0.001, 'enet__l': 0.2},\n",
        " {'enet__alpha': 0.001, 'enet__l': 0.3},\n",
        " {'enet__alpha': 0.001, 'enet__l': 0.4},\n",
        " {'enet__alpha': 0.001, 'enet__l': 0.5},\n",
        " {'enet__alpha': 0.001, 'enet__l': 0.6},\n",
        " {'enet__alpha': 0.001, 'enet__l': 0.7},\n",
        " {'enet__alpha': 0.001, 'enet__l': 0.8},\n",
        " {'enet__alpha': 0.001, 'enet__l': 0.9},\n",
        " {'enet__alpha': 0.01, 'enet__l': 0.1},\n",
        " {'enet__alpha': 0.01, 'enet__l': 0.2},\n",
        " {'enet__alpha': 0.01, 'enet__l': 0.3},\n",
        " {'enet__alpha': 0.01, 'enet__l': 0.4},\n",
        " {'enet__alpha': 0.01, 'enet__l': 0.5},\n",
        " {'enet__alpha': 0.01, 'enet__l': 0.6},\n",
        " {'enet__alpha': 0.01, 'enet__l': 0.7},\n",
        " {'enet__alpha': 0.01, 'enet__l': 0.8},\n",
        " {'enet__alpha': 0.01, 'enet__l': 0.9},\n",
        " {'enet__alpha': 0.1, 'enet__l': 0.1},\n",
        " {'enet__alpha': 0.1, 'enet__l': 0.2},\n",
        " {'enet__alpha': 0.1, 'enet__l': 0.3},\n",
        " {'enet__alpha': 0.1, 'enet__l': 0.4},\n",
        " {'enet__alpha': 0.1, 'enet__l': 0.5},\n",
        " {'enet__alpha': 0.1, 'enet__l': 0.6},\n",
        " {'enet__alpha': 0.1, 'enet__l': 0.7},\n",
        " {'enet__alpha': 0.1, 'enet__l': 0.8},\n",
        " {'enet__alpha': 0.1, 'enet__l': 0.9},\n",
        " {'enet__alpha': 1.0, 'enet__l': 0.1},\n",
        " {'enet__alpha': 1.0, 'enet__l': 0.2},\n",
        " {'enet__alpha': 1.0, 'enet__l': 0.3},\n",
        " {'enet__alpha': 1.0, 'enet__l': 0.4},\n",
        " {'enet__alpha': 1.0, 'enet__l': 0.5},\n",
        " {'enet__alpha': 1.0, 'enet__l': 0.6},\n",
        " {'enet__alpha': 1.0, 'enet__l': 0.7},\n",
        " {'enet__alpha': 1.0, 'enet__l': 0.8},\n",
        " {'enet__alpha': 1.0, 'enet__l': 0.9},\n",
        " {'enet__alpha': 10.0, 'enet__l': 0.1},\n",
        " {'enet__alpha': 10.0, 'enet__l': 0.2},\n",
        " {'enet__alpha': 10.0, 'enet__l': 0.3},\n",
        " {'enet__alpha': 10.0, 'enet__l': 0.4},\n",
        " {'enet__alpha': 10.0, 'enet__l': 0.5},\n",
        " {'enet__alpha': 10.0, 'enet__l': 0.6},\n",
        " {'enet__alpha': 10.0, 'enet__l': 0.7},\n",
        " {'enet__alpha': 10.0, 'enet__l': 0.8},\n",
        " {'enet__alpha': 10.0, 'enet__l': 0.9},\n",
        " {'enet__alpha': 100.0, 'enet__l': 0.1},\n",
        " {'enet__alpha': 100.0, 'enet__l': 0.2},\n",
        " {'enet__alpha': 100.0, 'enet__l': 0.3},\n",
        " {'enet__alpha': 100.0, 'enet__l': 0.4},\n",
        " {'enet__alpha': 100.0, 'enet__l': 0.5},\n",
        " {'enet__alpha': 100.0, 'enet__l': 0.6},\n",
        " {'enet__alpha': 100.0, 'enet__l': 0.7},\n",
        " {'enet__alpha': 100.0, 'enet__l': 0.8},\n",
        " {'enet__alpha': 100.0, 'enet__l': 0.9},\n",
        " {'enet__alpha': 1000.0, 'enet__l': 0.1},\n",
        " {'enet__alpha': 1000.0, 'enet__l': 0.2},\n",
        " {'enet__alpha': 1000.0, 'enet__l': 0.3},\n",
        " {'enet__alpha': 1000.0, 'enet__l': 0.4},\n",
        " {'enet__alpha': 1000.0, 'enet__l': 0.5},\n",
        " {'enet__alpha': 1000.0, 'enet__l': 0.6},\n",
        " {'enet__alpha': 1000.0, 'enet__l': 0.7},\n",
        " {'enet__alpha': 1000.0, 'enet__l': 0.8},\n",
        " {'enet__alpha': 1000.0, 'enet__l': 0.9}]"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "method_conf = JSONify_estimator(est, out=\"./est.json\")\n",
      "cv_conf = JSONify_cv(StratifiedKFold, cv_kwargs={\"n_folds\": 5},\n",
      "                     score_func=r2_score, \n",
      "                     stratified=True,\n",
      "                     inner_cv=StratifiedKFold,\n",
      "                     inner_cv_kwargs={\"n_folds\": 5},\n",
      "                     inner_score_func=r2_score,\n",
      "                     out=\"./cv.json\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset = build_dataset(X, y, method_conf, cv_conf, grid=grid, outputdir=\".\")\n",
      "wfi = create_wf(dataset['folds'], cv_conf, method_conf, \".\",\n",
      "               verbose=True)\n",
      "wf = save_wf(wfi, \"./workflow.json\", mode=\"soma-workflow\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_0_0.pkl 0 --inner 0\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_0_1.pkl 0 --inner 1\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_0_2.pkl 0 --inner 2\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_0_3.pkl 0 --inner 3\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_0_4.pkl 0 --inner 4\n",
        "\n",
        "python mempamal/scripts/inner_reducer.py ./cv.json ./est.json ./dataset.joblib ./red_res_0.pkl ./map_res_0_{inner}.pkl 0\n",
        "\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_1_0.pkl 1 --inner 0\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_1_1.pkl 1 --inner 1\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_1_2.pkl 1 --inner 2\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_1_3.pkl 1 --inner 3\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_1_4.pkl 1 --inner 4\n",
        "\n",
        "python mempamal/scripts/inner_reducer.py ./cv.json ./est.json ./dataset.joblib ./red_res_1.pkl ./map_res_1_{inner}.pkl 1\n",
        "\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_2_0.pkl 2 --inner 0\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_2_1.pkl 2 --inner 1\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_2_2.pkl 2 --inner 2\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_2_3.pkl 2 --inner 3\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_2_4.pkl 2 --inner 4\n",
        "\n",
        "python mempamal/scripts/inner_reducer.py ./cv.json ./est.json ./dataset.joblib ./red_res_2.pkl ./map_res_2_{inner}.pkl 2\n",
        "\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_3_0.pkl 3 --inner 0\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_3_1.pkl 3 --inner 1\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_3_2.pkl 3 --inner 2\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_3_3.pkl 3 --inner 3\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_3_4.pkl 3 --inner 4\n",
        "\n",
        "python mempamal/scripts/inner_reducer.py ./cv.json ./est.json ./dataset.joblib ./red_res_3.pkl ./map_res_3_{inner}.pkl 3\n",
        "\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_4_0.pkl 4 --inner 0\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_4_1.pkl 4 --inner 1\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_4_2.pkl 4 --inner 2\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_4_3.pkl 4 --inner 3\n",
        "python mempamal/scripts/mapper.py ./cv.json ./est.json ./dataset.joblib ./map_res_4_4.pkl 4 --inner 4\n",
        "\n",
        "python mempamal/scripts/inner_reducer.py ./cv.json ./est.json ./dataset.joblib ./red_res_4.pkl ./map_res_4_{inner}.pkl 4\n",
        "\n",
        "python mempamal/scripts/outer_reducer.py ./final_res.pkl ./red_res_{outer}.pkl\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from soma_workflow.client import WorkflowController\n",
      "\n",
      "import time\n",
      "import json\n",
      "import sklearn.externals.joblib as joblib\n",
      "\n",
      "controler = WorkflowController()\n",
      "wf_id = controler.submit_workflow(workflow=wf, name=\"third example\")\n",
      "\n",
      "while controler.workflow_status(wf_id) != 'workflow_done':\n",
      "    time.sleep(2)\n",
      "print(joblib.load('./final_res.pkl'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "light mode\n",
        "{'std': 0.020656791606087112, 'raw': array([ 0.90915869,  0.95577803,  0.93911917,  0.93473957,  0.89903826]), 'median': 0.93473957120188889, 'mean': 0.92756674426881069}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    }
   ],
   "metadata": {}
  }
 ]
}